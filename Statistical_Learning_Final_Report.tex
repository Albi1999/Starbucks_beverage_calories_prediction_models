% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Statistical Learning Final Report},
  pdfauthor={Alberto Calabrese, Eleonora Mesaglio, Greta d'Amore Grelli},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Statistical Learning Final Report}
\author{Alberto Calabrese, Eleonora Mesaglio, Greta d'Amore Grelli}
\date{2024-06-09}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{3}
\tableofcontents
}
\section{Introduction}\label{introduction}

Here Eleonora you can write the introduction of the project describing
the scope and the data used.

Thank you Albi, I will. What is our project scope though?

I think that we have to analyze the dataset and perform some statistical
analysis on it. We can start by calculating the correlation matrix and
then we can visualize the data through histograms, pairplots, barplots
and boxplots. Finally, we can perform a regression analysis.

\section{Data}\label{data}

The dataset we will analyze in this project is \emph{Starbucks Beverage
Components} from Kaggle, that you can find at the following link:
\url{https://www.kaggle.com/datasets/henryshan/starbucks}.

This data provides a comprehensive guide to the nutritional content of
the beverages available on the Starbucks menu. We have a total of
\(242\) samples described by \(18\) variables. These attributes include
the name of the beverage, its categorization and preparation method, the
total caloric content and the constituents of the beverage.

In the upcoming code lines, we import the dataset and generate a summary
visualization. This initial step allows us to gain a better
understanding of the data structure and the variables involved.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"Data/starbucks.csv"}\NormalTok{, }\AttributeTok{header =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{sep =} \StringTok{","}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection{Data Transformation}\label{data-transformation}

Note that several variables in our dataset, namely
``Vitamin.A\ldots.DV.'', ``Vitamin.C\ldots.DV.'', ``Calcium\ldots.DV.''
and ``Iron\ldots.DV.'', are represented as percentages. Consequently,
the percentage symbol is included in our data. However, when conducting
statistical analysis using R, the presence of non-numeric characters
such as the percentage symbol can cause complications, interfering with
the processing and analysis of the data. Therefore, we proceed to remove
it.

Similarly, as R primarily operates on numeric and categorical data, we
also convert all the other numerical variables into numeric format.

These preprocessing steps ensure a smooth and efficient analysis, making
it easier to explore, visualize, and understand our data.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Remove percentage sign from the data}
\NormalTok{data}\SpecialCharTok{$}\NormalTok{Vitamin.C....DV. }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(}\FunctionTok{gsub}\NormalTok{(}\StringTok{"\%"}\NormalTok{, }\StringTok{""}\NormalTok{, data}\SpecialCharTok{$}\NormalTok{Vitamin.C....DV.))}
\CommentTok{\# Set the other variables as numeric}
\NormalTok{data}\SpecialCharTok{$}\NormalTok{Calories }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{Calories)}
\end{Highlighting}
\end{Shaded}

\subsection{Data Cleaning}\label{data-cleaning}

Another challenge we have to face is the presence of missing data.
Indeed, in ``Caffeine..mg.'' column there are some NA values. This is a
common issue in data analysis and needs to be addressed appropriately to
ensure the validity of our statistical results.

One way to deal with these unwanted NA values is to omit the samples
containing them from our study. This guarantees that our analysis is
conducted solely on complete and dependable data. Alternatively, we can
fill them in with the average or the median of the observed values for
that specific attribute. This second method helps to preserve the
overall data distribution while addressing the missing data points.

In our work, we opt for the latter approach, replacing NA values with
the median. This choice is particularly suitable for our data, which is
skewed and contains outliers. Indeed, the median, being a measure of
central tendency that is not affected by extreme values, provides a more
robust replacement in the presence of outliers.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Summary of the Caffeine column}
\FunctionTok{summary}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{Caffeine..mg.)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's 
##    0.00   50.00   75.00   89.52  142.50  410.00      23
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Replace NA values with the median}
\NormalTok{data\_cleaned }\OtherTok{\textless{}{-}}\NormalTok{ data}
\NormalTok{data\_cleaned}\SpecialCharTok{$}\NormalTok{Caffeine..mg.[}\FunctionTok{is.na}\NormalTok{(data\_cleaned}\SpecialCharTok{$}\NormalTok{Caffeine..mg.)] }\OtherTok{\textless{}{-}} \FunctionTok{median}\NormalTok{(}
\NormalTok{  data\_cleaned}\SpecialCharTok{$}\NormalTok{Caffeine..mg., }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{)}
\CommentTok{\# Summary of the Caffeine column after cleaning}
\FunctionTok{summary}\NormalTok{(data\_cleaned}\SpecialCharTok{$}\NormalTok{Caffeine..mg.)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    0.00   70.00   75.00   88.14  130.00  410.00
\end{verbatim}

Lastly, taking in consideration our cleaned data, we renamed the columns
by removing dots and units of measure, in order to obtain a more
readable dataset.

\section{Correlation Analysis}\label{correlation-analysis}

After completing these preliminary preprocessing steps, we calculate the
correlation matrix for our dataset. This computation helps us in
comprehending the interrelationships among the dataset's variables. In
the correlation matrix, a value near to \(1\) at the \(ij\) position
indicates a strong positive correlation between the \(i\)-th and
\(j\)-th variables. Conversely, a value close to \(-1\) signifies a
strong negative correlation. A value near \(0\) suggests that the two
variables do not significantly influence each other.

Observe that the first three columns of our data are categorical
features, thus for these we cannot compute Pearson's correlation
coefficient. In the following code lines we remove them to compute and
plot such matrix.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Remove first 3 columns for the correlation matrix since them are categorical}
\NormalTok{data\_num }\OtherTok{\textless{}{-}}\NormalTok{ data\_cleaned[, }\FunctionTok{sapply}\NormalTok{(data\_cleaned, is.numeric)]}
\NormalTok{correlation\_matrix }\OtherTok{\textless{}{-}} \FunctionTok{cor}\NormalTok{(data\_num)}
\CommentTok{\# Plot the correlation matrix using corrplot}
\FunctionTok{corrplot}\NormalTok{(correlation\_matrix, }\AttributeTok{method =} \StringTok{"number"}\NormalTok{, }\AttributeTok{tl.col =} \StringTok{"black"}\NormalTok{, }
         \AttributeTok{tl.srt =} \DecValTok{45}\NormalTok{, }\AttributeTok{addCoef.col =} \StringTok{"black"}\NormalTok{, }\AttributeTok{number.cex =} \FloatTok{0.5}\NormalTok{, }\AttributeTok{tl.cex =} \FloatTok{0.7}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{Statistical_Learning_Final_Report_files/figure-latex/correlation_analysis-1} \end{center}

\section{Data Visualization}\label{data-visualization}

Data visualization is a powerful tool that allows us to uncover
patterns, correlations and outliers in our data. It provides visual
information on the dataset in our analysis, representing large amounts
of data in a clear and comprehensive way and underlining the
relationships among them. This enables us to recognize patterns quickly.

So, let us transform our raw data into graphical representations, to
gain a more comprehensive understanding of the information at hand.

\subsection{Histograms}\label{histograms}

Histograms serve as a graphical interpretation of data distribution. In
a histogram, each bar corresponds to the counted frequency within each
bin or interval. We introduce these plots to see if our data is normally
distributed, skewed, or has outlier values.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Histogram of the data with density distribution}
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{), }\AttributeTok{mar =} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\FunctionTok{ncol}\NormalTok{(data\_num)) \{}
  \FunctionTok{hist}\NormalTok{(data\_num[, i], }\AttributeTok{main =} \FunctionTok{colnames}\NormalTok{(data\_num)[i],}
       \AttributeTok{xlab =} \FunctionTok{colnames}\NormalTok{(data\_num)[i], }\AttributeTok{col =}\NormalTok{ col[i], }\AttributeTok{freq =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{  dens }\OtherTok{\textless{}{-}} \FunctionTok{density}\NormalTok{(data\_num[, i], }\AttributeTok{na.rm=}\ConstantTok{TRUE}\NormalTok{, }\AttributeTok{adjust=}\FloatTok{1.25}\NormalTok{)}
  \FunctionTok{lines}\NormalTok{(dens, }\AttributeTok{col =} \StringTok{"black"}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{2}\NormalTok{)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{Statistical_Learning_Final_Report_files/figure-latex/histograms-1} \end{center}

By looking at the graphs, we can notice that the variables ``Calories'',
``Total\_Carbohydrates'', ``Cholesterol'', and ``Sugars'' exhibit
distributions that are nearly normal. Conversely, the distributions of
the remaining variables display a noticeable skewness towards the left.

\subsection{Pairplot}\label{pairplot}

\textbf{io questi li toglierei. tanto spazio}

We will plot a pairplot to visualize the relationship between the
variables. The pairplot is a grid of scatterplots that shows the
relationship between each pair of variables in the dataset. This
visualization helps us to identify patterns and correlations between the
variables.

First of all we have to define the function for the pairplot. We will
define a function for the histogram, the correlation and the smooth
line.

Then we create the pairplot using the defined functions.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pairs}\NormalTok{(data\_num, }
      \AttributeTok{diag.panel =}\NormalTok{ panel.hist,}
      \AttributeTok{upper.panel =}\NormalTok{ panel.cor, }
      \AttributeTok{lower.panel =}\NormalTok{ panel.smooth,}
      \AttributeTok{colour =} \StringTok{"\#4ea5ff"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{Statistical_Learning_Final_Report_files/figure-latex/pairplot-1} \end{center}

ADD COMMENTS ON THE GRAPH

\subsection{Barplot}\label{barplot}

We will now plot the bar plots for our dataset. The primary use of bar
plots is to make comparisons between the amounts of different
categories. Indeed, each bar corresponds to a category and the height of
the bar represents the frequency or proportion of that category. These
graphs are commonly used for categorical data, or numerical data that
has been binned into categories.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{), }\AttributeTok{mar =} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\FunctionTok{ncol}\NormalTok{(data\_num)) \{}
  \FunctionTok{barplot}\NormalTok{(}\FunctionTok{table}\NormalTok{(data\_num[, i]), }\AttributeTok{main =} \FunctionTok{colnames}\NormalTok{(data\_num)[i],}
          \AttributeTok{xlab =} \FunctionTok{colnames}\NormalTok{(data\_num)[i], }\AttributeTok{col =}\NormalTok{ col[i], }\AttributeTok{border =}\NormalTok{ col[i])}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{Statistical_Learning_Final_Report_files/figure-latex/barplot-1} \end{center}

We can deduce some useful information by looking at these plots.

For example, we can notice that variables such as ``Saturated\_Fat'',
``Dietary\_Fibre'', ``Vitamin\_C'', and ``Iron'' are typically either
absent or present in small quantities in the beverages. In particular,
the frequency of these variables rapidly diminishes as their levels
increase. On the other hand, the variables ``Calories'', ``Total\_Fat'',
``Trans\_Fat'', and ``Total\_Carbohydrates'' show a wide range of values
across different beverage types, going from high levels in some
beverages to minimal amounts in others.

We can further observe that the distribution of ``Vitamin\_A'' appears
to be more evenly spread among the different levels in various
beverages, while instead ``Caffeine'' plot is interesting as it exhibits
three distinct peaks in frequency.

\subsubsection{Beverages Barplot}\label{beverages-barplot}

As previously anticipated, bar plots also allows us to see the
distribution of categorical variables like ``Beverage\_category'' and
``Beverage\_prep''. In this way we can identify the most frequently
occurring beverages and their preparation methods.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar =} \FunctionTok{c}\NormalTok{(}\DecValTok{8}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\FunctionTok{barplot}\NormalTok{(}\FunctionTok{table}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{Beverage\_category),}
        \AttributeTok{main =} \StringTok{"Distribution of Beverage Categories"}\NormalTok{,}
        \AttributeTok{ylab =} \StringTok{"Count"}\NormalTok{, }\AttributeTok{col =} \StringTok{"\#4ea5ff"}\NormalTok{, }\AttributeTok{las =} \DecValTok{2}\NormalTok{, }\AttributeTok{cex.names =} \FloatTok{0.6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{Statistical_Learning_Final_Report_files/figure-latex/beverage_barplot-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{barplot}\NormalTok{(}\FunctionTok{table}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{Beverage\_prep),}
        \AttributeTok{main =} \StringTok{"Distribution of Beverage Preparation"}\NormalTok{,}
        \AttributeTok{ylab =} \StringTok{"Count"}\NormalTok{, }\AttributeTok{col =} \StringTok{"\#ff810f"}\NormalTok{, }\AttributeTok{las =} \DecValTok{2}\NormalTok{, }\AttributeTok{cex.names =} \FloatTok{0.6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{Statistical_Learning_Final_Report_files/figure-latex/beverage_barplot-2} \end{center}

At this point, we aim to compare the total calorie content among
different beverage categories. To do so, we first aggregate the data to
obtain the total calories for each beverage category. Secondly, we
construct a bar plot to visually represent the results.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar =} \FunctionTok{c}\NormalTok{(}\DecValTok{8}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\NormalTok{total\_calories\_by\_category }\OtherTok{\textless{}{-}} \FunctionTok{aggregate}\NormalTok{(Calories }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Beverage\_category,}
                                        \AttributeTok{data =}\NormalTok{ data\_cleaned, sum)}
\FunctionTok{barplot}\NormalTok{(}\AttributeTok{height =}\NormalTok{ total\_calories\_by\_category}\SpecialCharTok{$}\NormalTok{Calories,}
        \AttributeTok{names.arg =}\NormalTok{ total\_calories\_by\_category}\SpecialCharTok{$}\NormalTok{Beverage\_category,}
        \AttributeTok{main =} \StringTok{"Total Calories by Beverage Category"}\NormalTok{,}
        \AttributeTok{ylab =} \StringTok{"Total Calories"}\NormalTok{, }\AttributeTok{col =} \StringTok{"\#4ea5ff"}\NormalTok{, }\AttributeTok{las =} \DecValTok{2}\NormalTok{, }\AttributeTok{cex.names =} \FloatTok{0.6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{Statistical_Learning_Final_Report_files/figure-latex/total_calories-1} \end{center}

Similarly, we compare the total sugars for each beverage preparation,
gathering data to obtain the total sugars for each preparation of
beverage and successively creating a bar plot.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar =} \FunctionTok{c}\NormalTok{(}\DecValTok{8}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\NormalTok{total\_sugar\_by\_prep }\OtherTok{\textless{}{-}} \FunctionTok{aggregate}\NormalTok{(Total\_Carbohydrates }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Beverage\_prep,}
                                 \AttributeTok{data =}\NormalTok{ data\_cleaned, sum)}
\FunctionTok{barplot}\NormalTok{(}\AttributeTok{height =}\NormalTok{ total\_sugar\_by\_prep}\SpecialCharTok{$}\NormalTok{Total\_Carbohydrates,}
        \AttributeTok{names.arg =}\NormalTok{ total\_sugar\_by\_prep}\SpecialCharTok{$}\NormalTok{Beverage\_prep,}
        \AttributeTok{main =} \StringTok{"Total Sugars by Beverage Preparation"}\NormalTok{,}
        \AttributeTok{ylab =} \StringTok{"Total Sugars (g)"}\NormalTok{, }\AttributeTok{col =} \StringTok{"\#ff810f"}\NormalTok{, }\AttributeTok{las =} \DecValTok{2}\NormalTok{, }\AttributeTok{cex.names =} \FloatTok{0.6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{Statistical_Learning_Final_Report_files/figure-latex/total_sugars-1} \end{center}

\subsection{Boxplot}\label{boxplot}

We will plot a boxplot of the data. The boxplot is a graphical
representation of the data that displays the distribution of the data,
including the median, quartiles, and outliers. This visualization helps
us to identify the spread and variability of the data.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DecValTok{5}\NormalTok{), }\AttributeTok{mar =} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\FunctionTok{ncol}\NormalTok{(data\_num)) \{}
  \FunctionTok{boxplot}\NormalTok{(data\_num[, i], }\AttributeTok{main =} \FunctionTok{colnames}\NormalTok{(data\_num)[i],}
          \AttributeTok{xlab =} \FunctionTok{colnames}\NormalTok{(data\_num)[i], }\AttributeTok{col =}\NormalTok{ col[i])}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{Statistical_Learning_Final_Report_files/figure-latex/boxplot-1} \end{center}

\subsection{Scatterplot}\label{scatterplot}

We will plot a scatterplot of the data. The scatterplot is a graphical
representation of the data that displays the relationship between two
variables. This visualization helps us to identify patterns and
correlations between the variables.

We create a scatterplot to compare the amounts of calories and fat for
each categories of bevarage. We assign distinct colors to each beverage
category and create a legend to identify each category.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Set the variable as factor}
\NormalTok{data\_cleaned}\SpecialCharTok{$}\NormalTok{Beverage\_category }\OtherTok{\textless{}{-}} \FunctionTok{as.factor}\NormalTok{(data\_cleaned}\SpecialCharTok{$}\NormalTok{Beverage\_category)}
\NormalTok{colors }\OtherTok{\textless{}{-}} \FunctionTok{rainbow}\NormalTok{(}\FunctionTok{length}\NormalTok{(}\FunctionTok{unique}\NormalTok{(data\_cleaned}\SpecialCharTok{$}\NormalTok{Beverage\_category)))}
\NormalTok{color\_map }\OtherTok{\textless{}{-}} \FunctionTok{setNames}\NormalTok{(colors, }\FunctionTok{levels}\NormalTok{(data\_cleaned}\SpecialCharTok{$}\NormalTok{Beverage\_category))}
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(data\_cleaned}\SpecialCharTok{$}\NormalTok{Calories, }
\NormalTok{     data\_cleaned}\SpecialCharTok{$}\NormalTok{Total\_Fat\_g,}
     \AttributeTok{col =}\NormalTok{ color\_map[data\_cleaned}\SpecialCharTok{$}\NormalTok{Beverage\_category],}
     \AttributeTok{pch =} \DecValTok{19}\NormalTok{, }\AttributeTok{xlab =} \StringTok{"Calories"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Total Fat (g)"}\NormalTok{,}
     \AttributeTok{main =} \StringTok{"Calories vs Total Fat"}\NormalTok{)}
\FunctionTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\AttributeTok{legend =} \FunctionTok{levels}\NormalTok{(data\_cleaned}\SpecialCharTok{$}\NormalTok{Beverage\_category), }
       \AttributeTok{col =}\NormalTok{ colors, }\AttributeTok{cex =} \FloatTok{0.4}\NormalTok{, }\AttributeTok{pch =} \DecValTok{19}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{Statistical_Learning_Final_Report_files/figure-latex/fat_comparison-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Numeric variable {-}\textgreater{} calculate density}
\NormalTok{total\_fat\_density }\OtherTok{\textless{}{-}} \FunctionTok{density}\NormalTok{(data\_cleaned}\SpecialCharTok{$}\NormalTok{Total\_Fat)}
\NormalTok{trans\_fat\_density }\OtherTok{\textless{}{-}} \FunctionTok{density}\NormalTok{(data\_cleaned}\SpecialCharTok{$}\NormalTok{Trans\_Fat)}
\FunctionTok{plot}\NormalTok{(total\_fat\_density, }\AttributeTok{col =} \StringTok{"\#4ea5ff"}\NormalTok{,}
     \AttributeTok{main =} \StringTok{"Comparison of Total Fat and Trans Fat Distributions"}\NormalTok{, }
     \AttributeTok{xlab =} \StringTok{"Fat Content (g)"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Density"}\NormalTok{, }
     \AttributeTok{ylim =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FunctionTok{max}\NormalTok{(total\_fat\_density}\SpecialCharTok{$}\NormalTok{y, trans\_fat\_density}\SpecialCharTok{$}\NormalTok{y)),}
     \AttributeTok{xlim =} \FunctionTok{range}\NormalTok{(data\_cleaned}\SpecialCharTok{$}\NormalTok{Total\_Fat, data\_cleaned}\SpecialCharTok{$}\NormalTok{Trans\_Fat), }
     \AttributeTok{lwd =} \DecValTok{2}\NormalTok{, }\AttributeTok{lty =} \DecValTok{1}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(trans\_fat\_density, }\AttributeTok{col =} \StringTok{"\#ff810f"}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{2}\NormalTok{, }\AttributeTok{lty =} \DecValTok{1}\NormalTok{)}
\FunctionTok{legend}\NormalTok{(}\StringTok{"topright"}\NormalTok{, }\AttributeTok{legend =} \FunctionTok{c}\NormalTok{(}\StringTok{"Total Fat"}\NormalTok{, }\StringTok{"Trans Fat"}\NormalTok{),}
       \AttributeTok{col =} \FunctionTok{c}\NormalTok{(}\StringTok{"\#4ea5ff"}\NormalTok{, }\StringTok{"\#ff810f"}\NormalTok{), }\AttributeTok{lwd =} \DecValTok{2}\NormalTok{, }\AttributeTok{lty =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{Statistical_Learning_Final_Report_files/figure-latex/fat_comparison-2} \end{center}

Create scatterplot to look into relantionship between calories and other
variables. We will plot the relationship between calories and sodium,
protein, vitamin C and fiber.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{mar =} \FunctionTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\FunctionTok{with}\NormalTok{(data\_cleaned, \{}
  \FunctionTok{plot}\NormalTok{(Calories, Sodium , }\AttributeTok{main =} \StringTok{"Relation between Calories and Sodium"}\NormalTok{,}
       \AttributeTok{xlab =} \StringTok{"Calories"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Sodium (mg)"}\NormalTok{, }\AttributeTok{col =}\NormalTok{ col[}\DecValTok{1}\NormalTok{])}
  \FunctionTok{plot}\NormalTok{(Calories, Protein , }\AttributeTok{main =} \StringTok{"Relation between Calories and Protein"}\NormalTok{,}
       \AttributeTok{xlab =} \StringTok{"Calories"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Protein (g)"}\NormalTok{, }\AttributeTok{col =}\NormalTok{ col[}\DecValTok{5}\NormalTok{])}
  \FunctionTok{plot}\NormalTok{(Calories, Vitamin\_C , }\AttributeTok{main =} \StringTok{"Relation between Calories and Vitamin C"}\NormalTok{,}
       \AttributeTok{xlab =} \StringTok{"Calories"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Vitamin C (mg)"}\NormalTok{, }\AttributeTok{col =}\NormalTok{ col[}\DecValTok{10}\NormalTok{])}
  \FunctionTok{plot}\NormalTok{(Calories, Cholesterol , }\AttributeTok{main =} \StringTok{"Relation between Calories and Fiber"}\NormalTok{,}
       \AttributeTok{xlab =} \StringTok{"Calories"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Fiber (g)"}\NormalTok{, }\AttributeTok{col =}\NormalTok{ col[}\DecValTok{15}\NormalTok{])}
\NormalTok{\})}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{Statistical_Learning_Final_Report_files/figure-latex/scatterplot-1} \end{center}

There's increase in every feature with increase in calories. Features
like proteins and fiber rapidly increase, instead vitamin and
cholesterol more flat growing. Confirmed by correlation coefficients

ADD COMMENTS ON THE GRAPH

\section{Regression Analysis}\label{regression-analysis}

\subsection{Linear Regression}\label{linear-regression}

Linear regression model to predict the amount of calories based on the
amount of the other variables We use the lm() function to fit a linear
regression model

\subsubsection{Simple Linear Regression}\label{simple-linear-regression}

Fit linear simple regression with just one variable on data\_cleaned,
looking at correlation plot we choose Sugars due to high correlation.

This code will fit a simple linear regression model predicting
``Calories'' using ``Sugars'' as the predictor variable and provide a
summary of the model.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm\_simple }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(Calories }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Sugars, }\AttributeTok{data =}\NormalTok{ data\_cleaned)}
\FunctionTok{kable}\NormalTok{(}\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{AIC =} \FunctionTok{AIC}\NormalTok{(lm\_simple), }\AttributeTok{BIC =} \FunctionTok{BIC}\NormalTok{(lm\_simple),}
                 \AttributeTok{R\_squared =} \FunctionTok{summary}\NormalTok{(lm\_simple)}\SpecialCharTok{$}\NormalTok{r.squared, }
                 \AttributeTok{adj\_R\_squared =} \FunctionTok{summary}\NormalTok{(lm\_simple)}\SpecialCharTok{$}\NormalTok{adj.r.squared), }
      \AttributeTok{caption =} \StringTok{"Model evaluation metrics for the simple linear regression model"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}rrrr@{}}
\caption{Model evaluation metrics for the simple linear regression
model}\tabularnewline
\toprule\noalign{}
AIC & BIC & R\_squared & adj\_R\_squared \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
AIC & BIC & R\_squared & adj\_R\_squared \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
2509.036 & 2519.503 & 0.8275094 & 0.8267907 \\
\end{longtable}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{mar =} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(lm\_simple)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{Statistical_Learning_Final_Report_files/figure-latex/simple_linear_regression-1} \end{center}

The coefficient for ``Sugars'' (\(4.7426\)) indicates that, on average,
for every one-unit increase in ``Sugars'', the predicted ``Calories''
increases by approximately \(4.7426\) units. Both the intercept and the
coefficient for ``Sugars'' are statistically significant
(\(p < 0.001\)), indicating a strong linear relationship between
``Sugars'' and ``Calories''. The F-statistic is highly significant
(\(p < 2.2e-16\)), indicating that the overall regression model is
statistically significant in explaining the variance in ``Calories''.
Model Fit:The adjusted R-squared value (\(0.8268\)) indicates that
approximately \(82.68%
\) of the variance in ``Calories'' can be explained by the predictor
variable ``Sugars''. Overall, this output suggests that the simple
linear regression model provides a statistically significant
relationship between ``Sugars'' and ``Calories'', with ``Sugars'' being
a strong predictor of ``Calories''. However, the AIC and BIC values
suggest that there might be other models that provide a better fit for
the data. Summarizing the model is too simple so it doesn't capture the
complexity of the data, so we try to fit a multiple linear regression
model.

\subsubsection{Multiple Linear
Regression}\label{multiple-linear-regression}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm\_model }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ data\_num\_)}
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{mar =} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(lm\_model)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{Statistical_Learning_Final_Report_files/figure-latex/linear_regression-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{kable}\NormalTok{(}\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{AIC =} \FunctionTok{AIC}\NormalTok{(lm\_model), }\AttributeTok{BIC =} \FunctionTok{BIC}\NormalTok{(lm\_model),}
                 \AttributeTok{R\_squared =} \FunctionTok{summary}\NormalTok{(lm\_model)}\SpecialCharTok{$}\NormalTok{r.squared, }
                 \AttributeTok{adj\_R\_squared =} \FunctionTok{summary}\NormalTok{(lm\_model)}\SpecialCharTok{$}\NormalTok{adj.r.squared),}
      \AttributeTok{caption =} \StringTok{"Model evaluation metrics for the linear regression model"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}rrrr@{}}
\caption{Model evaluation metrics for the linear regression
model}\tabularnewline
\toprule\noalign{}
AIC & BIC & R\_squared & adj\_R\_squared \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
AIC & BIC & R\_squared & adj\_R\_squared \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1494.304 & 1550.127 & 0.9976608 & 0.9975166 \\
\end{longtable}

The model has a low AIC and BIC values, the R-squared value is \(0.997\)
so the model is a good fit for the data.

\subsubsection{Backward Elimination}\label{backward-elimination}

Now we apply the selection of the predictors with the backward
elimination method.

\begin{verbatim}
## Start:  AIC=805.54
## y ~ Total_Fat + Trans_Fat + Saturated_Fat + Sodium + Total_Carbohydrates + 
##     Cholesterol + Dietary_Fibre + Sugars + Protein + Vitamin_A + 
##     Vitamin_C + Calcium + Iron + Caffeine
## 
##                       Df Sum of Sq     RSS     AIC
## - Saturated_Fat        1       7.7  5972.5  803.85
## <none>                              5964.8  805.54
## - Dietary_Fibre        1      69.7  6034.6  806.35
## - Sodium               1      73.0  6037.9  806.48
## - Vitamin_A            1      98.9  6063.7  807.52
## - Caffeine             1     141.4  6106.2  809.21
## - Total_Carbohydrates  1     209.9  6174.8  811.91
## - Trans_Fat            1     246.3  6211.2  813.33
## - Vitamin_C            1     252.1  6216.9  813.56
## - Sugars               1     277.2  6242.0  814.53
## - Calcium              1     277.4  6242.2  814.54
## - Protein              1     496.5  6461.4  822.89
## - Cholesterol          1    1817.0  7781.9  867.89
## - Iron                 1    2217.1  8181.9  880.02
## - Total_Fat            1   11494.4 17459.3 1063.44
## 
## Step:  AIC=803.85
## y ~ Total_Fat + Trans_Fat + Sodium + Total_Carbohydrates + Cholesterol + 
##     Dietary_Fibre + Sugars + Protein + Vitamin_A + Vitamin_C + 
##     Calcium + Iron + Caffeine
## 
##                       Df Sum of Sq     RSS     AIC
## <none>                              5972.5  803.85
## - Dietary_Fibre        1      66.4  6038.9  804.52
## - Vitamin_A            1      97.3  6069.8  805.76
## - Caffeine             1     148.3  6120.9  807.79
## - Total_Carbohydrates  1     208.5  6181.0  810.15
## - Trans_Fat            1     243.0  6215.6  811.50
## - Vitamin_C            1     264.3  6236.8  812.33
## - Sugars               1     269.6  6242.2  812.54
## - Calcium              1     316.7  6289.3  814.35
## - Protein              1     495.1  6467.6  821.12
## - Sodium               1     519.0  6491.5  822.02
## - Cholesterol          1    1930.5  7903.0  869.63
## - Iron                 1    2231.7  8204.2  878.68
## - Total_Fat            1   14183.1 20155.6 1096.20
\end{verbatim}

\begin{verbatim}
## 
## Call:
## lm(formula = y ~ Total_Fat + Trans_Fat + Sodium + Total_Carbohydrates + 
##     Cholesterol + Dietary_Fibre + Sugars + Protein + Vitamin_A + 
##     Vitamin_C + Calcium + Iron + Caffeine, data = data_num_)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -14.0113  -3.4396  -0.3132   3.0241  21.8261 
## 
## Coefficients:
##                      Estimate Std. Error t value Pr(>|t|)    
## (Intercept)          0.197087   0.945878   0.208 0.835131    
## Total_Fat           11.012071   0.473256  23.269  < 2e-16 ***
## Trans_Fat           -2.344729   0.769780  -3.046 0.002592 ** 
## Sodium              -0.358660   0.080576  -4.451 1.34e-05 ***
## Total_Carbohydrates  0.020897   0.007407   2.821 0.005206 ** 
## Cholesterol          2.864251   0.333647   8.585 1.43e-15 ***
## Dietary_Fibre        1.491635   0.937246   1.592 0.112881    
## Sugars               1.095752   0.341539   3.208 0.001527 ** 
## Protein              2.215506   0.509614   4.347 2.08e-05 ***
## Vitamin_A            0.160911   0.083492   1.927 0.055189 .  
## Vitamin_C            0.150364   0.047341   3.176 0.001698 ** 
## Calcium              0.480189   0.138098   3.477 0.000607 ***
## Iron                -0.650683   0.070496  -9.230  < 2e-16 ***
## Caffeine             0.013789   0.005795   2.380 0.018153 *  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 5.118 on 228 degrees of freedom
## Multiple R-squared:  0.9977, Adjusted R-squared:  0.9975 
## F-statistic:  7471 on 13 and 228 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{center}\includegraphics{Statistical_Learning_Final_Report_files/figure-latex/backward_elimination-1} \end{center}

\begin{longtable}[]{@{}rrrr@{}}
\caption{Model evaluation metrics for the linear regression model with
backward elimination}\tabularnewline
\toprule\noalign{}
AIC & BIC & R\_squared & adj\_R\_squared \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
AIC & BIC & R\_squared & adj\_R\_squared \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1492.616 & 1544.95 & 0.9976578 & 0.9975243 \\
\end{longtable}

The backward selection drops only the variable ``Saturated\_Fat'' since
it's not considered significant in explaining the amount of calories
mantaining the other variables.

Comarison between the models

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{kable}\NormalTok{(}\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{Model =} \FunctionTok{c}\NormalTok{(}\StringTok{"Simple Linear Regression"}\NormalTok{, }\StringTok{"Multiple Linear Regression"}\NormalTok{,}
                           \StringTok{"Multiple Linear Regression with Backward Elimination"}\NormalTok{),}
                 \AttributeTok{AIC =} \FunctionTok{c}\NormalTok{(}\FunctionTok{AIC}\NormalTok{(lm\_simple), }\FunctionTok{AIC}\NormalTok{(lm\_model), }\FunctionTok{AIC}\NormalTok{(backward\_model)),}
                 \AttributeTok{BIC =} \FunctionTok{c}\NormalTok{(}\FunctionTok{BIC}\NormalTok{(lm\_simple), }\FunctionTok{BIC}\NormalTok{(lm\_model), }\FunctionTok{BIC}\NormalTok{(backward\_model)),}
                 \AttributeTok{R\_squared =} \FunctionTok{c}\NormalTok{(}\FunctionTok{summary}\NormalTok{(lm\_simple)}\SpecialCharTok{$}\NormalTok{r.squared, }
                               \FunctionTok{summary}\NormalTok{(lm\_model)}\SpecialCharTok{$}\NormalTok{r.squared, }
                               \FunctionTok{summary}\NormalTok{(backward\_model)}\SpecialCharTok{$}\NormalTok{r.squared),}
                 \AttributeTok{adj\_R\_squared =} \FunctionTok{c}\NormalTok{(}\FunctionTok{summary}\NormalTok{(lm\_simple)}\SpecialCharTok{$}\NormalTok{adj.r.squared, }
                                   \FunctionTok{summary}\NormalTok{(lm\_model)}\SpecialCharTok{$}\NormalTok{adj.r.squared, }
                                   \FunctionTok{summary}\NormalTok{(backward\_model)}\SpecialCharTok{$}\NormalTok{adj.r.squared)),}
      \AttributeTok{caption =} \StringTok{"Model comparison"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.5579}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.0947}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.0947}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1053}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1474}}@{}}
\caption{Model comparison}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Model
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
AIC
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
BIC
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
R\_squared
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
adj\_R\_squared
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Model
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
AIC
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
BIC
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
R\_squared
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
adj\_R\_squared
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Simple Linear Regression & 2509.036 & 2519.503 & 0.8275094 &
0.8267907 \\
Multiple Linear Regression & 1494.304 & 1550.127 & 0.9976608 &
0.9975166 \\
Multiple Linear Regression with Backward Elimination & 1492.616 &
1544.950 & 0.9976578 & 0.9975243 \\
\end{longtable}

The multiple linear regression model with backward elimination has the
lowest AIC and BIC values, the highest R-squared value, and the highest
adjusted R-squared value, indicating that it is the best model for
predicting the amount of calories based on the amount of the other
variables.

Coefficients: Both models have very similar coefficients for the
variables that were retained. The removal of ``Saturated\_Fat'' in the
backward model did not significantly affect the estimates of the other
coefficients.

Significance of Variables: In the full model, ``Saturated\_Fat'' had a
high p-value (\(0.589\)), indicating it was not a significant variable.
In the backward model, ``Saturated\_Fat'' was removed, slightly
improving the AIC while keeping all other variables significant.

Overall Performance: Both models perform very similarly in terms of
R-squared and residual standard error. The backward model is preferable
because it has a slightly lower AIC, suggesting it is a more
parsimonious model without sacrificing the quality of the fit.

\subsubsection{Anova}\label{anova}

Anova comparison between the models

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{anova\_results }\OtherTok{\textless{}{-}} \FunctionTok{anova}\NormalTok{(lm\_model, backward\_model)}
\NormalTok{anova\_results}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Analysis of Variance Table
## 
## Model 1: y ~ Total_Fat + Trans_Fat + Saturated_Fat + Sodium + Total_Carbohydrates + 
##     Cholesterol + Dietary_Fibre + Sugars + Protein + Vitamin_A + 
##     Vitamin_C + Calcium + Iron + Caffeine
## Model 2: y ~ Total_Fat + Trans_Fat + Sodium + Total_Carbohydrates + Cholesterol + 
##     Dietary_Fibre + Sugars + Protein + Vitamin_A + Vitamin_C + 
##     Calcium + Iron + Caffeine
##   Res.Df    RSS Df Sum of Sq      F Pr(>F)
## 1    227 5964.8                           
## 2    228 5972.5 -1   -7.6917 0.2927  0.589
\end{verbatim}

Degrees of Freedom (Res.Df): The full model has \(227\) degrees of
freedom, while the backward model has \(228\). This is because we
removed one variable from the full model.

Residual Sum of Squares (RSS): The full model has an RSS of \(5964.83\),
while the backward model has an RSS of \(5972.55\). This indicates that
the difference between the two models in terms of residual error is very
small.

Sum of Squares (Sum of Sq): The difference between the two models in
terms of sum of squares is \(-7.7235\), indicating that the removed
variable (``Saturated\_Fat'') does not significantly contribute to
explaining the variability in calories.

F-statistic (F): The F value is \(0.2937\) with a p-value of \(0.588\).
This high p-value indicates that there is no significant difference
between the two models. In other words, the reduced model is not
significantly worse than the full model.

Conclusion: The ANOVA shows that the removal of the ``Saturated\_Fat''
variable does not have a significant impact on the model. This confirms
that the model obtained through backward selection is more parsimonious
without compromising the quality of the fit. Therefore, the backward
model is preferable to the full model.

\subsubsection{Multicollinearity}\label{multicollinearity}

To check for multicollinearity, we calculate the Variance Inflation
Factors (VIF) for the variables in the multiple linear regression model,
it measures how much the variance of the estimated coefficients is
increased due to multicollinearity.Usually a VIF value greater than
\(10\) indicates a problematic amount of multicollinearity.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{kable}\NormalTok{(}\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{VIF =} \FunctionTok{vif}\NormalTok{(backward\_model)),}
      \AttributeTok{caption =} \StringTok{"VIF values for the linear regression model"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lr@{}}
\caption{VIF values for the linear regression model}\tabularnewline
\toprule\noalign{}
& VIF \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
& VIF \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Total\_Fat & 17.863697 \\
Trans\_Fat & 14.667324 \\
Sodium & 4.448925 \\
Total\_Carbohydrates & 3.419094 \\
Cholesterol & 442.886703 \\
Dietary\_Fibre & 16.896773 \\
Sugars & 417.769822 \\
Protein & 56.706156 \\
Vitamin\_A & 4.205667 \\
Vitamin\_C & 4.288442 \\
Calcium & 37.105615 \\
Iron & 5.027804 \\
Caffeine & 1.176323 \\
\end{longtable}

However as we can see from the \emph{Table X} e have a problem with
multicollinearity, the VIF values are high for some variables, so we
have to act on the data to solve this problem

The high values of the VIF could be due to:

\begin{itemize}
\item
  High correlation between variables,means that variable contribuite in
  the same way to predict and explain calories
\item
  Same information
\item
  Data unbalanced
\item
  Different Measurement Scales: If the variables in the model have
  significantly different measurement scales such as g and mg this could
  affect the VIF values.
\item
  Non-linear Relationships: If the relationships between the variables
  are non-linear, this could also affect the VIF values.
\end{itemize}

In this case, normalizing the variables might help reduce
multicollinearity.

\subsubsection{Standardize the data}\label{standardize-the-data}

We have tried different kind of standardization to reduce the
multicollinearity First at all we tried the scale by standard
normalization The negative value of the AIC (\(-748.2623\)) indicates
that the standardized linear regression model provides a better
compromise between data fit and model complexity compared to the
reference model. However, the VIF values are still high, indicating that
multicollinearity is still present in the model.

To reduce the problem of high VIF in linear regression, it is generally
preferable to use the transformation that includes both log
transformation and standardization of the data. This is because
standardization helps to put all variables on the same scale, reducing
the likelihood of multicollinearity. Log transformation: Reduces the
variance of the variables, making the distribution more normal and
reducing the impact of outliers. Standardization: Puts all variables on
a common scale, with mean \(0\) and standard deviation \(1\), further
reducing multicollinearity.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{std\_data\_log }\OtherTok{\textless{}{-}} \FunctionTok{scale}\NormalTok{(}\FunctionTok{log}\NormalTok{(data\_num }\SpecialCharTok{+} \DecValTok{1}\NormalTok{)) }\CommentTok{\# Standardize the data}
\NormalTok{std\_data\_log\_df }\OtherTok{\textless{}{-}} \FunctionTok{as.data.frame}\NormalTok{(std\_data\_log) }\CommentTok{\# Set as dataframe}
\NormalTok{mod\_log\_tr }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(Calories }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ std\_data\_log\_df)}
\FunctionTok{kable}\NormalTok{(}\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{AIC =} \FunctionTok{AIC}\NormalTok{(mod\_log\_tr), }\AttributeTok{BIC =} \FunctionTok{BIC}\NormalTok{(mod\_log\_tr),}
                 \AttributeTok{R\_squared =} \FunctionTok{summary}\NormalTok{(mod\_log\_tr)}\SpecialCharTok{$}\NormalTok{r.squared, }
                 \AttributeTok{adj\_R\_squared =} \FunctionTok{summary}\NormalTok{(mod\_log\_tr)}\SpecialCharTok{$}\NormalTok{adj.r.squared), }
      \AttributeTok{caption =} \StringTok{"Model evaluation metrics for the log transformed data"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}rrrr@{}}
\caption{Model evaluation metrics for the log transformed
data}\tabularnewline
\toprule\noalign{}
AIC & BIC & R\_squared & adj\_R\_squared \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
AIC & BIC & R\_squared & adj\_R\_squared \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
-53.42411 & 2.398897 & 0.9586932 & 0.9561457 \\
\end{longtable}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{kable}\NormalTok{(}\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{VIF =} \FunctionTok{vif}\NormalTok{(mod\_log\_tr)),}
      \AttributeTok{caption =} \StringTok{"VIF values for the log transformed data"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lr@{}}
\caption{VIF values for the log transformed data}\tabularnewline
\toprule\noalign{}
& VIF \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
& VIF \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Total\_Fat & 12.049669 \\
Trans\_Fat & 10.577306 \\
Saturated\_Fat & 4.528080 \\
Sodium & 5.817088 \\
Total\_Carbohydrates & 4.363628 \\
Cholesterol & 39.988684 \\
Dietary\_Fibre & 7.115085 \\
Sugars & 38.415586 \\
Protein & 31.007121 \\
Vitamin\_A & 13.647581 \\
Vitamin\_C & 2.196674 \\
Calcium & 25.873742 \\
Iron & 4.582594 \\
Caffeine & 1.310005 \\
\end{longtable}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{mar =} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(mod\_log\_tr)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{Statistical_Learning_Final_Report_files/figure-latex/standardization-1} \end{center}

The model has a low AIC and BIC values, the R-squared value is \(0.95\)
so the model is a good fit for the data. However we have still
collinearity, so we try to use backward elimination to check if this
method will removes the variables that are not significant in the model.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{backward\_model\_log }\OtherTok{\textless{}{-}} \FunctionTok{step}\NormalTok{(mod\_log\_tr, }\AttributeTok{direction =} \StringTok{"backward"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Start:  AIC=-742.19
## Calories ~ Total_Fat + Trans_Fat + Saturated_Fat + Sodium + Total_Carbohydrates + 
##     Cholesterol + Dietary_Fibre + Sugars + Protein + Vitamin_A + 
##     Vitamin_C + Calcium + Iron + Caffeine
## 
##                       Df Sum of Sq     RSS     AIC
## - Vitamin_A            1    0.0002  9.9552 -744.18
## - Sodium               1    0.0037  9.9586 -744.10
## - Caffeine             1    0.0108  9.9657 -743.93
## - Calcium              1    0.0169  9.9718 -743.78
## - Saturated_Fat        1    0.0189  9.9739 -743.73
## - Vitamin_C            1    0.0420  9.9969 -743.17
## - Iron                 1    0.0547 10.0096 -742.86
## <none>                              9.9549 -742.19
## - Total_Carbohydrates  1    0.1562 10.1111 -740.42
## - Protein              1    0.2674 10.2223 -737.78
## - Dietary_Fibre        1    0.2858 10.2407 -737.34
## - Sugars               1    0.3671 10.3220 -735.43
## - Trans_Fat            1    0.9397 10.8946 -722.36
## - Total_Fat            1    1.6148 11.5697 -707.81
## - Cholesterol          1    7.3885 17.3434 -609.85
## 
## Step:  AIC=-744.18
## Calories ~ Total_Fat + Trans_Fat + Saturated_Fat + Sodium + Total_Carbohydrates + 
##     Cholesterol + Dietary_Fibre + Sugars + Protein + Vitamin_C + 
##     Calcium + Iron + Caffeine
## 
##                       Df Sum of Sq     RSS     AIC
## - Sodium               1    0.0035  9.9587 -746.10
## - Caffeine             1    0.0106  9.9658 -745.93
## - Calcium              1    0.0172  9.9724 -745.77
## - Saturated_Fat        1    0.0194  9.9745 -745.71
## - Vitamin_C            1    0.0425  9.9977 -745.15
## - Iron                 1    0.0546 10.0097 -744.86
## <none>                              9.9552 -744.18
## - Total_Carbohydrates  1    0.1560 10.1112 -742.42
## - Dietary_Fibre        1    0.2901 10.2453 -739.23
## - Protein              1    0.3302 10.2854 -738.29
## - Sugars               1    0.3911 10.3463 -736.86
## - Trans_Fat            1    0.9469 10.9021 -724.20
## - Total_Fat            1    1.6315 11.5867 -709.46
## - Cholesterol          1    7.7956 17.7508 -606.23
## 
## Step:  AIC=-746.1
## Calories ~ Total_Fat + Trans_Fat + Saturated_Fat + Total_Carbohydrates + 
##     Cholesterol + Dietary_Fibre + Sugars + Protein + Vitamin_C + 
##     Calcium + Iron + Caffeine
## 
##                       Df Sum of Sq     RSS     AIC
## - Caffeine             1    0.0121  9.9707 -747.81
## - Calcium              1    0.0159  9.9746 -747.71
## - Saturated_Fat        1    0.0166  9.9753 -747.70
## - Vitamin_C            1    0.0416 10.0002 -747.09
## - Iron                 1    0.0518 10.0104 -746.84
## <none>                              9.9587 -746.10
## - Total_Carbohydrates  1    0.1627 10.1213 -744.18
## - Dietary_Fibre        1    0.2867 10.2454 -741.23
## - Protein              1    0.3523 10.3110 -739.69
## - Sugars               1    0.4005 10.3592 -738.56
## - Trans_Fat            1    1.1608 11.1195 -721.42
## - Total_Fat            1    1.9717 11.9304 -704.38
## - Cholesterol          1    7.8478 17.8065 -607.47
## 
## Step:  AIC=-747.81
## Calories ~ Total_Fat + Trans_Fat + Saturated_Fat + Total_Carbohydrates + 
##     Cholesterol + Dietary_Fibre + Sugars + Protein + Vitamin_C + 
##     Calcium + Iron
## 
##                       Df Sum of Sq     RSS     AIC
## - Saturated_Fat        1    0.0139  9.9847 -749.47
## - Calcium              1    0.0170  9.9877 -749.39
## - Iron                 1    0.0506 10.0214 -748.58
## - Vitamin_C            1    0.0586 10.0293 -748.39
## <none>                              9.9707 -747.81
## - Total_Carbohydrates  1    0.1544 10.1251 -746.09
## - Dietary_Fibre        1    0.2945 10.2653 -742.76
## - Protein              1    0.3714 10.3422 -740.96
## - Sugars               1    0.4081 10.3789 -740.10
## - Trans_Fat            1    1.1509 11.1216 -723.37
## - Total_Fat            1    1.9666 11.9374 -706.24
## - Cholesterol          1    7.8592 17.8299 -609.15
## 
## Step:  AIC=-749.47
## Calories ~ Total_Fat + Trans_Fat + Total_Carbohydrates + Cholesterol + 
##     Dietary_Fibre + Sugars + Protein + Vitamin_C + Calcium + 
##     Iron
## 
##                       Df Sum of Sq     RSS     AIC
## - Calcium              1    0.0200 10.0047 -750.98
## - Vitamin_C            1    0.0491 10.0338 -750.28
## - Iron                 1    0.0632 10.0478 -749.94
## <none>                              9.9847 -749.47
## - Total_Carbohydrates  1    0.1593 10.1440 -747.64
## - Dietary_Fibre        1    0.3385 10.3231 -743.40
## - Protein              1    0.3826 10.3673 -742.37
## - Sugars               1    0.4035 10.3882 -741.88
## - Trans_Fat            1    1.1828 11.1675 -724.38
## - Total_Fat            1    2.1313 12.1160 -704.65
## - Cholesterol          1    7.8453 17.8300 -611.15
## 
## Step:  AIC=-750.98
## Calories ~ Total_Fat + Trans_Fat + Total_Carbohydrates + Cholesterol + 
##     Dietary_Fibre + Sugars + Protein + Vitamin_C + Iron
## 
##                       Df Sum of Sq    RSS     AIC
## - Vitamin_C            1    0.0354 10.040 -752.13
## <none>                             10.005 -750.98
## - Iron                 1    0.0947 10.099 -750.71
## - Total_Carbohydrates  1    0.1395 10.144 -749.63
## - Dietary_Fibre        1    0.3687 10.373 -744.23
## - Sugars               1    0.4520 10.457 -742.29
## - Trans_Fat            1    1.5074 11.512 -719.02
## - Protein              1    1.5699 11.575 -717.71
## - Total_Fat            1    2.8305 12.835 -692.69
## - Cholesterol          1    8.1349 18.140 -608.98
## 
## Step:  AIC=-752.13
## Calories ~ Total_Fat + Trans_Fat + Total_Carbohydrates + Cholesterol + 
##     Dietary_Fibre + Sugars + Protein + Iron
## 
##                       Df Sum of Sq    RSS     AIC
## - Iron                 1    0.0659 10.106 -752.55
## <none>                             10.040 -752.13
## - Total_Carbohydrates  1    0.1934 10.233 -749.51
## - Sugars               1    0.4577 10.498 -743.34
## - Dietary_Fibre        1    0.6314 10.671 -739.37
## - Trans_Fat            1    1.5040 11.544 -720.35
## - Protein              1    1.5424 11.582 -719.55
## - Total_Fat            1    2.8360 12.876 -693.92
## - Cholesterol          1    8.0999 18.140 -610.98
## 
## Step:  AIC=-752.55
## Calories ~ Total_Fat + Trans_Fat + Total_Carbohydrates + Cholesterol + 
##     Dietary_Fibre + Sugars + Protein
## 
##                       Df Sum of Sq    RSS     AIC
## <none>                             10.106 -752.55
## - Total_Carbohydrates  1    0.1569 10.263 -750.82
## - Sugars               1    0.4654 10.571 -743.65
## - Trans_Fat            1    1.4382 11.544 -722.35
## - Dietary_Fibre        1    1.7801 11.886 -715.29
## - Protein              1    1.8258 11.932 -714.36
## - Total_Fat            1    2.8708 12.977 -694.04
## - Cholesterol          1    8.1106 18.216 -611.96
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{kable}\NormalTok{(}\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{AIC =} \FunctionTok{AIC}\NormalTok{(backward\_model\_log), }\AttributeTok{BIC =} \FunctionTok{BIC}\NormalTok{(backward\_model\_log),}
                 \AttributeTok{R\_squared =} \FunctionTok{summary}\NormalTok{(backward\_model\_log)}\SpecialCharTok{$}\NormalTok{r.squared, }
                 \AttributeTok{adj\_R\_squared =} \FunctionTok{summary}\NormalTok{(backward\_model\_log)}\SpecialCharTok{$}\NormalTok{adj.r.squared), }
      \AttributeTok{caption =} \StringTok{"Model evaluation metrics for the log transformed data }
\StringTok{      with backward elimination"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}rrrr@{}}
\caption{Model evaluation metrics for the log transformed data with
backward elimination}\tabularnewline
\toprule\noalign{}
AIC & BIC & R\_squared & adj\_R\_squared \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
AIC & BIC & R\_squared & adj\_R\_squared \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
-63.78109 & -32.38065 & 0.9580667 & 0.9568123 \\
\end{longtable}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{kable}\NormalTok{(}\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{VIF =} \FunctionTok{vif}\NormalTok{(backward\_model\_log)),}
      \AttributeTok{caption =} \StringTok{"VIF values for the log transformed data with backward elimination"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lr@{}}
\caption{VIF values for the log transformed data with backward
elimination}\tabularnewline
\toprule\noalign{}
& VIF \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
& VIF \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Total\_Fat & 5.823786 \\
Trans\_Fat & 5.161252 \\
Total\_Carbohydrates & 3.390622 \\
Cholesterol & 36.628698 \\
Dietary\_Fibre & 1.851534 \\
Sugars & 33.948827 \\
Protein & 2.976444 \\
\end{longtable}

AIC slightly worst and the VIF values are still high, indicating that
multicollinearity is still present in the model. So we try to remove
manually the variables that has high VIF values.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mod\_log\_tr\_updated }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(Calories }\SpecialCharTok{\textasciitilde{}}\NormalTok{ . }\SpecialCharTok{{-}}\NormalTok{ Cholesterol }\SpecialCharTok{{-}}\NormalTok{ Sugars,}
                         \AttributeTok{data =}\NormalTok{ std\_data\_log\_df)}
\FunctionTok{kable}\NormalTok{(}\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{VIF =} \FunctionTok{vif}\NormalTok{(mod\_log\_tr\_updated)),}
      \AttributeTok{caption =} \StringTok{"VIF values for the log transformed data with}\SpecialCharTok{\textbackslash{}n}
\StringTok{      manual removal of variables"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Table: VIF values for the log transformed data with

\begin{verbatim}
  manual removal of variables
\end{verbatim}

\begin{longtable}[]{@{}lr@{}}
\toprule\noalign{}
& VIF \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Total\_Fat & 11.902918 \\
Trans\_Fat & 10.114112 \\
Saturated\_Fat & 4.466975 \\
Sodium & 5.782843 \\
Total\_Carbohydrates & 3.375194 \\
Dietary\_Fibre & 7.080360 \\
Protein & 26.902392 \\
Vitamin\_A & 12.396739 \\
Vitamin\_C & 1.985799 \\
Calcium & 25.519022 \\
Iron & 4.521552 \\
Caffeine & 1.295121 \\
\end{longtable}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mod\_log\_tr\_backward\_2 }\OtherTok{\textless{}{-}} \FunctionTok{step}\NormalTok{(mod\_log\_tr\_updated, }\AttributeTok{direction =} \StringTok{"backward"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Start:  AIC=-220.91
## Calories ~ (Total_Fat + Trans_Fat + Saturated_Fat + Sodium + 
##     Total_Carbohydrates + Cholesterol + Dietary_Fibre + Sugars + 
##     Protein + Vitamin_A + Vitamin_C + Calcium + Iron + Caffeine) - 
##     Cholesterol - Sugars
## 
##                       Df Sum of Sq     RSS     AIC
## - Dietary_Fibre        1    0.0121  87.251 -222.88
## - Total_Fat            1    0.1126  87.351 -222.60
## - Calcium              1    0.1806  87.419 -222.41
## - Sodium               1    0.2021  87.441 -222.35
## - Trans_Fat            1    0.5358  87.774 -221.43
## - Iron                 1    0.5624  87.801 -221.36
## - Saturated_Fat        1    0.5958  87.834 -221.26
## - Caffeine             1    0.6473  87.886 -221.12
## <none>                              87.239 -220.91
## - Vitamin_A            1    1.0670  88.305 -219.97
## - Protein              1    1.6336  88.872 -218.42
## - Vitamin_C            1    6.4240  93.663 -205.72
## - Total_Carbohydrates  1   27.0741 114.313 -157.50
## 
## Step:  AIC=-222.88
## Calories ~ Total_Fat + Trans_Fat + Saturated_Fat + Sodium + Total_Carbohydrates + 
##     Protein + Vitamin_A + Vitamin_C + Calcium + Iron + Caffeine
## 
##                       Df Sum of Sq     RSS     AIC
## - Total_Fat            1    0.1006  87.351 -224.60
## - Sodium               1    0.2120  87.463 -224.29
## - Calcium              1    0.3197  87.570 -223.99
## - Saturated_Fat        1    0.5841  87.835 -223.26
## - Trans_Fat            1    0.5988  87.849 -223.22
## - Caffeine             1    0.6376  87.888 -223.12
## <none>                              87.251 -222.88
## - Iron                 1    0.8319  88.083 -222.58
## - Vitamin_A            1    1.1061  88.357 -221.83
## - Protein              1    2.9198  90.170 -216.91
## - Vitamin_C            1    6.6568  93.907 -207.08
## - Total_Carbohydrates  1   27.2737 114.524 -159.05
## 
## Step:  AIC=-224.6
## Calories ~ Trans_Fat + Saturated_Fat + Sodium + Total_Carbohydrates + 
##     Protein + Vitamin_A + Vitamin_C + Calcium + Iron + Caffeine
## 
##                       Df Sum of Sq     RSS     AIC
## - Sodium               1    0.1308  87.482 -226.24
## - Saturated_Fat        1    0.4841  87.835 -225.26
## - Calcium              1    0.5994  87.951 -224.94
## - Caffeine             1    0.6821  88.033 -224.72
## <none>                              87.351 -224.60
## - Vitamin_A            1    1.0214  88.373 -223.78
## - Iron                 1    1.1762  88.528 -223.36
## - Trans_Fat            1    2.6009  89.952 -219.50
## - Protein              1    2.9421  90.293 -218.58
## - Vitamin_C            1    6.9456  94.297 -208.08
## - Total_Carbohydrates  1   28.2259 115.577 -158.84
## 
## Step:  AIC=-226.24
## Calories ~ Trans_Fat + Saturated_Fat + Total_Carbohydrates + 
##     Protein + Vitamin_A + Vitamin_C + Calcium + Iron + Caffeine
## 
##                       Df Sum of Sq     RSS     AIC
## - Saturated_Fat        1    0.3536  87.836 -227.26
## - Calcium              1    0.4828  87.965 -226.90
## <none>                              87.482 -226.24
## - Caffeine             1    0.7305  88.213 -226.22
## - Iron                 1    1.0837  88.566 -225.26
## - Vitamin_A            1    1.3358  88.818 -224.57
## - Protein              1    2.8413  90.323 -220.50
## - Trans_Fat            1    2.9927  90.475 -220.10
## - Vitamin_C            1    6.8307  94.313 -210.04
## - Total_Carbohydrates  1   28.3018 115.784 -160.41
## 
## Step:  AIC=-227.26
## Calories ~ Trans_Fat + Total_Carbohydrates + Protein + Vitamin_A + 
##     Vitamin_C + Calcium + Iron + Caffeine
## 
##                       Df Sum of Sq     RSS     AIC
## - Calcium              1    0.4405  88.276 -228.05
## - Caffeine             1    0.6573  88.493 -227.46
## <none>                              87.836 -227.26
## - Vitamin_A            1    1.1556  88.991 -226.10
## - Iron                 1    2.1821  90.018 -223.32
## - Protein              1    2.5694  90.405 -222.28
## - Trans_Fat            1    3.9060  91.742 -218.73
## - Vitamin_C            1    6.5080  94.344 -211.96
## - Total_Carbohydrates  1   28.8548 116.691 -160.52
## 
## Step:  AIC=-228.05
## Calories ~ Trans_Fat + Total_Carbohydrates + Protein + Vitamin_A + 
##     Vitamin_C + Iron + Caffeine
## 
##                       Df Sum of Sq     RSS     AIC
## - Caffeine             1     0.672  88.949 -228.21
## <none>                              88.276 -228.05
## - Protein              1     2.152  90.428 -224.22
## - Vitamin_A            1     2.169  90.445 -224.18
## - Iron                 1     2.389  90.666 -223.59
## - Trans_Fat            1     3.843  92.120 -219.74
## - Vitamin_C            1     6.239  94.515 -213.52
## - Total_Carbohydrates  1    34.846 123.122 -149.53
## 
## Step:  AIC=-228.21
## Calories ~ Trans_Fat + Total_Carbohydrates + Protein + Vitamin_A + 
##     Vitamin_C + Iron
## 
##                       Df Sum of Sq     RSS     AIC
## <none>                              88.949 -228.21
## - Vitamin_A            1     2.482  91.431 -223.55
## - Iron                 1     2.499  91.447 -223.51
## - Protein              1     2.836  91.784 -222.62
## - Trans_Fat            1     3.430  92.379 -221.06
## - Vitamin_C            1     9.634  98.583 -205.33
## - Total_Carbohydrates  1    38.906 127.855 -142.41
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{kable}\NormalTok{(}\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{AIC =} \FunctionTok{AIC}\NormalTok{(mod\_log\_tr\_backward\_2), }\AttributeTok{BIC =} \FunctionTok{BIC}\NormalTok{(mod\_log\_tr\_backward\_2),}
                 \AttributeTok{R\_squared =} \FunctionTok{summary}\NormalTok{(mod\_log\_tr\_backward\_2)}\SpecialCharTok{$}\NormalTok{r.squared, }
                 \AttributeTok{adj\_R\_squared =} \FunctionTok{summary}\NormalTok{(mod\_log\_tr\_backward\_2)}\SpecialCharTok{$}\NormalTok{adj.r.squared), }
      \AttributeTok{caption =} \StringTok{"Model evaluation metrics for the log transformed data with}
\StringTok{      backward elimination and manual removal of variables"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}rrrr@{}}
\caption{Model evaluation metrics for the log transformed data with
backward elimination and manual removal of variables}\tabularnewline
\toprule\noalign{}
AIC & BIC & R\_squared & adj\_R\_squared \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
AIC & BIC & R\_squared & adj\_R\_squared \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
460.5536 & 488.4651 & 0.6309185 & 0.6214952 \\
\end{longtable}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{mar =} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(mod\_log\_tr\_backward\_2)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{Statistical_Learning_Final_Report_files/figure-latex/backward_elimination_log_2-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{kable}\NormalTok{(}\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{VIF =} \FunctionTok{vif}\NormalTok{(mod\_log\_tr\_backward\_2)),}
      \AttributeTok{caption =} \StringTok{"VIF values for the log transformed data with backward }
\StringTok{      elimination and manual removal of variables"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lr@{}}
\caption{VIF values for the log transformed data with backward
elimination and manual removal of variables}\tabularnewline
\toprule\noalign{}
& VIF \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
& VIF \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Trans\_Fat & 1.491986 \\
Total\_Carbohydrates & 2.649737 \\
Protein & 10.478245 \\
Vitamin\_A & 8.772514 \\
Vitamin\_C & 1.241962 \\
Iron & 1.304571 \\
\end{longtable}

The VIF values are now below \(10\), indicating that multicollinearity
has been reduced in the model. The R-squared value is decreased but it
is still good.

Model Diagnostics: Non-normal residuals suggest that some assumptions of
linear regression might be violated. Specifically, the assumption of
normality of the residuals is not met, this can affect the validity of
hypothesis tests on the coefficients and predictions.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{shapiro.test}\NormalTok{((}\FunctionTok{residuals}\NormalTok{(mod\_log\_tr\_backward\_2)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Shapiro-Wilk normality test
## 
## data:  (residuals(mod_log_tr_backward_2))
## W = 0.82171, p-value = 5.816e-16
\end{verbatim}

Given the p-value is significantly smaller than \(0.05\), we reject the
null hypothesis. This indicates that the residuals of the model
mod\_log\_tr\_backward\_2 do not follow a normal distribution. In this
case, W is quite a bit lower than \(1\), suggesting the residuals
deviate from normality. Sol Robust Methods: Use robust regression
methods that do not assume normality of errors

We have tried other trasformation like min-max scaling and robust
scaling but not satisfactory due to VIF still to high. Regularization:
Using regularization methods such as ridge regression or lasso
regression penalizes the coefficients of variables, helping to reduce
multicollinearity.

\subsection{Lasso Regression}\label{lasso-regression}

We use the glmnet package to fit a lasso regression model. Lasso
regression is a type of linear regression that uses L1 regularization to
penalize the coefficients of the model. This helps to prevent
overfitting and select the most important features in the data.

First we standardize the data and then we fit the lasso regression model
using the cv.glmnet() function. We use cross-validation to select the
optimal lambda value for the model. The lambda value that minimizes the
mean squared error (MSE) is selected as the optimal lambda value. The
optimal lambda value is used to fit the final lasso regression model.

Lasso regression tends to shrink the coefficients of less important
variables towards zero, effectively performing variable selection. By
eliminating irrelevant variables from the model, it reduces the number
of predictors and thereby reduces multicollinearity. Lasso tends to
produce sparse solutions, meaning it drives many coefficients to exactly
zero. When variables are removed from the model, the multicollinearity
among predictors decreases, leading to lower VIF values. It performs
automatic features selection by shrinking some coefficients to zero.
This feature selection process inherently removes redundant variables
and reduces multicollinearity in the model.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{std\_data }\OtherTok{\textless{}{-}} \FunctionTok{as.data.frame}\NormalTok{(}\FunctionTok{scale}\NormalTok{(data\_num)) }\CommentTok{\# Standardize the data}
\NormalTok{mod\_lasso }\OtherTok{\textless{}{-}} \FunctionTok{cv.glmnet}\NormalTok{(}\AttributeTok{x =} \FunctionTok{as.matrix}\NormalTok{(std\_data[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{]),}
                       \AttributeTok{y =}\NormalTok{ std\_data}\SpecialCharTok{$}\NormalTok{Calories,}
                       \AttributeTok{alpha =} \DecValTok{1}\NormalTok{, }\AttributeTok{standardize =} \ConstantTok{FALSE}\NormalTok{)}
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(mod\_lasso)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{Statistical_Learning_Final_Report_files/figure-latex/lasso_regression-1} \end{center}

The lasso regression model selects the most important features in the
data and penalizes the coefficients of the model. The model has a low
AIC and BIC values, the R-squared value is \(0.99\) so the model is a
good fit for the data.

\subsection{Ridge Regression}\label{ridge-regression}

We use the glmnet package to fit a ridge regression model. Ridge
regression is a type of linear regression that uses L2 regularization to
penalize the coefficients of the model. This helps to prevent
overfitting and reduce the impact of collinearity in the data.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mod\_ridge }\OtherTok{\textless{}{-}} \FunctionTok{cv.glmnet}\NormalTok{(}\AttributeTok{x =} \FunctionTok{as.matrix}\NormalTok{(std\_data[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{]),}
                       \AttributeTok{y =}\NormalTok{ std\_data}\SpecialCharTok{$}\NormalTok{Calories,}
                       \AttributeTok{alpha =} \DecValTok{0}\NormalTok{, }\AttributeTok{standardize =} \ConstantTok{FALSE}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(mod\_ridge)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{Statistical_Learning_Final_Report_files/figure-latex/ridge_regression-1} \end{center}

The ridge regression model reduces the impact of collinearity in the
data and penalizes the coefficients of the model. The model has a low
AIC and BIC values, the R-squared value is \(0.99\) so the model is a
good fit for the data.

\subsection{Model Comparison}\label{model-comparison}

We compare the linear regression, lasso regression, and ridge regression
models to select the best model for predicting the amount of calories
based on the amount of the other variables. We evaluate the models using
the R-squared value, and the Mean Squared Error (MSE) for each model.

The R-squared value is a measure of how well the model fits the data, it
ranges from \(0\) to \(1\), with higher values indicating a better fit

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lasso\_pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(mod\_lasso, }\AttributeTok{s =} \StringTok{"lambda.min"}\NormalTok{, }
                      \AttributeTok{newx =} \FunctionTok{as.matrix}\NormalTok{(std\_data[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{]))}
\NormalTok{lasso\_r\_squared }\OtherTok{\textless{}{-}} \FunctionTok{cor}\NormalTok{(lasso\_pred, std\_data}\SpecialCharTok{$}\NormalTok{Calories)}\SpecialCharTok{\^{}}\DecValTok{2}
\NormalTok{ridge\_pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(mod\_ridge, }\AttributeTok{s =} \StringTok{"lambda.min"}\NormalTok{, }
                      \AttributeTok{newx =} \FunctionTok{as.matrix}\NormalTok{(std\_data[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{]))}
\NormalTok{ridge\_r\_squared }\OtherTok{\textless{}{-}} \FunctionTok{cor}\NormalTok{(ridge\_pred, std\_data}\SpecialCharTok{$}\NormalTok{Calories)}\SpecialCharTok{\^{}}\DecValTok{2}

\FunctionTok{kable}\NormalTok{(}\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{Model =} \FunctionTok{c}\NormalTok{(}\StringTok{"Linear Regression"}\NormalTok{, }\StringTok{"Lasso Regression"}\NormalTok{,}
                           \StringTok{"Ridge Regression"}\NormalTok{),}
                 \AttributeTok{R\_squared =} \FunctionTok{c}\NormalTok{(}\FunctionTok{summary}\NormalTok{(lm\_model)}\SpecialCharTok{$}\NormalTok{r.squared,}
\NormalTok{                               lasso\_r\_squared, ridge\_r\_squared)), }
      \AttributeTok{caption =} \StringTok{"R{-}squared values for the models"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lr@{}}
\caption{R-squared values for the models}\tabularnewline
\toprule\noalign{}
Model & R\_squared \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
Model & R\_squared \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Linear Regression & 0.9976608 \\
Lasso Regression & 0.9975756 \\
Ridge Regression & 0.9941815 \\
\end{longtable}

\subsection{Model Evaluation}\label{model-evaluation}

We evaluate the performance of the linear regression, lasso regression,
and ridge regression models using the mean squared error (MSE). The MSE
is a measure of the average squared difference between the predicted and
actual values. Lower values of the MSE indicate better performance of
the model.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{linear\_pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(lm\_model, }\AttributeTok{newdata =}\NormalTok{ data\_num)}
\NormalTok{linear\_mse }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{((linear\_pred }\SpecialCharTok{{-}}\NormalTok{ data\_num}\SpecialCharTok{$}\NormalTok{Calories)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{lasso\_mse }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{((lasso\_pred }\SpecialCharTok{{-}}\NormalTok{ std\_data}\SpecialCharTok{$}\NormalTok{Calories)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{ridge\_mse }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{((ridge\_pred }\SpecialCharTok{{-}}\NormalTok{ std\_data}\SpecialCharTok{$}\NormalTok{Calories)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}

\FunctionTok{kable}\NormalTok{(}\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{Model =} \FunctionTok{c}\NormalTok{(}\StringTok{"Linear Regression"}\NormalTok{,}
                           \StringTok{"Lasso Regression"}\NormalTok{, }\StringTok{"Ridge Regression"}\NormalTok{),}
                 \AttributeTok{MSE =} \FunctionTok{c}\NormalTok{(linear\_mse, lasso\_mse, ridge\_mse)), }
      \AttributeTok{caption =} \StringTok{"MSE values for the models"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lr@{}}
\caption{MSE values for the models}\tabularnewline
\toprule\noalign{}
Model & MSE \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
Model & MSE \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Linear Regression & 24.6481166 \\
Lasso Regression & 0.0024158 \\
Ridge Regression & 0.0066477 \\
\end{longtable}

We choose the model with the highest R-squared value and the lowest MSE
as the best model for predicting the amount of calories based on the
amount of the other variables. The best model is the lasso because it
has the lowest value for R\^{}2 and MSE and it is the most robust model.

\subsection{Cross Validation}\label{cross-validation}

Cross validation is a technique used to evaluate the performance of a
model. It involves splitting the data into training and testing sets,
fitting the model using the training set, and evaluating the model using
the testing set. This process is repeated multiple times to ensure that
the model is robust and generalizes well to new data.

We split the data into training and testing sets, fit the lasso
regression model using the training set.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\NormalTok{train\_index }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\FunctionTok{nrow}\NormalTok{(std\_data), }\FloatTok{0.8} \SpecialCharTok{*} \FunctionTok{nrow}\NormalTok{(std\_data))}
\NormalTok{train\_data }\OtherTok{\textless{}{-}}\NormalTok{ std\_data[train\_index, ]}
\NormalTok{test\_data }\OtherTok{\textless{}{-}}\NormalTok{ std\_data[}\SpecialCharTok{{-}}\NormalTok{train\_index, ]}
\CommentTok{\# Fit the lasso regression model on the training data}
\NormalTok{mod\_lasso\_train }\OtherTok{\textless{}{-}} \FunctionTok{cv.glmnet}\NormalTok{(}\AttributeTok{x =} \FunctionTok{as.matrix}\NormalTok{(train\_data[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{]),}
                             \AttributeTok{y =}\NormalTok{ train\_data}\SpecialCharTok{$}\NormalTok{Calories,}
                             \AttributeTok{alpha =} \DecValTok{1}\NormalTok{, }\AttributeTok{standardize =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

We evaluate the model using the testing set. We make predictions using
the testing set and calculate the mean squared error and the root mean
squared error to assess the model's accuracy.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lasso\_pred\_test }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(mod\_lasso\_train, }\AttributeTok{s =} \StringTok{"lambda.min"}\NormalTok{,}
                           \AttributeTok{newx =} \FunctionTok{as.matrix}\NormalTok{(test\_data[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{]))}
\CommentTok{\# R{-}squared value of the lasso regression model on the test data}
\NormalTok{lasso\_r\_squared\_test }\OtherTok{\textless{}{-}} \FunctionTok{cor}\NormalTok{(lasso\_pred\_test, test\_data}\SpecialCharTok{$}\NormalTok{Calories)}\SpecialCharTok{\^{}}\DecValTok{2}
\CommentTok{\# MSE of the lasso regression model on the test data}
\NormalTok{lasso\_mse\_test }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{((lasso\_pred\_test }\SpecialCharTok{{-}}\NormalTok{ test\_data}\SpecialCharTok{$}\NormalTok{Calories)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The R-squared value and MSE are used to evaluate the performance of the
model on the test data.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Accuracy of the model}
\NormalTok{accuracy\_lm }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ (lasso\_mse\_test }\SpecialCharTok{/} \FunctionTok{var}\NormalTok{(test\_data}\SpecialCharTok{$}\NormalTok{Calories))}
\CommentTok{\# Plot the predicted values against the actual values on the test data}
\FunctionTok{plot}\NormalTok{(test\_data}\SpecialCharTok{$}\NormalTok{Calories, lasso\_pred\_test, }\AttributeTok{xlab =} \StringTok{"Actual Calories"}\NormalTok{,}
     \AttributeTok{ylab =} \StringTok{"Predicted Calories"}\NormalTok{, }\AttributeTok{main =} \StringTok{"Predicted vs Actual Calories"}\NormalTok{,}
     \AttributeTok{col =} \StringTok{"\#4ea5ff"}\NormalTok{, }\AttributeTok{pch =} \DecValTok{19}\NormalTok{)}
\FunctionTok{abline}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\AttributeTok{col =} \StringTok{"\#ff810f"}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{Statistical_Learning_Final_Report_files/figure-latex/accuracy_lm-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{kable}\NormalTok{(}\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{Accuracy =}\NormalTok{ accuracy\_lm, }\AttributeTok{MSE =}\NormalTok{ lasso\_mse\_test, }
                 \AttributeTok{R\_squared =}\NormalTok{ lasso\_r\_squared\_test),}
      \AttributeTok{caption =} \StringTok{"Model evaluation metrics on the test data"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lrrr@{}}
\caption{Model evaluation metrics on the test data}\tabularnewline
\toprule\noalign{}
& Accuracy & MSE & R\_squared \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
& Accuracy & MSE & R\_squared \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
lambda.min & 0.9979473 & 0.0026283 & 0.9979454 \\
\end{longtable}

As we can see from \emph{Table X} the R-squared value is \(0.997\),
indicating that the model explains \(99%
\) of the variance in the data and the MSE is \(0.002628338\),
indicating that the model has a low error rate. The accuracy of the
model is \(0.9979473\), indicating that the model is able to predict the
amount of calories with high accuracy. The plot shows the predicted
values against the actual values on the test data The points are close
to the diagonal line, indicating that the model is making accurate
predictions.

\end{document}
